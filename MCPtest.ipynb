{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c76a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import List, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage \n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e724b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    \"\"\"配置管理类，负责管理和验证环境变量\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"初始化配置并加载环境变量\"\"\"\n",
    "        self.load_env()\n",
    "        self._validate_env()\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_env() -> None:\n",
    "        \"\"\"从.env文件加载环境变量\"\"\"\n",
    "        load_dotenv()\n",
    "        \n",
    "    def _validate_env(self) -> None:\n",
    "        \"\"\"验证必需的环境变量是否存在\"\"\"\n",
    "        required_vars = [\"DEEPSEEK_API_KEY\"]\n",
    "        missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"缺少必需的环境变量: {', '.join(missing_vars)}\")\n",
    "    \n",
    "    @property\n",
    "    def api_key(self) -> str:\n",
    "        \"\"\"获取 DeepSeek API 密钥\"\"\"\n",
    "        return os.getenv(\"DEEPSEEK_API_KEY\", \"\")\n",
    "    \n",
    "    @property\n",
    "    def base_url(self) -> str:\n",
    "        \"\"\"获取 DeepSeek API 基础 URL\"\"\"\n",
    "        return os.getenv(\"DEEPSEEK_BASE_URL\", \"https://api.deepseek.com\")\n",
    "    \n",
    "    @property\n",
    "    def model(self) -> str:\n",
    "        \"\"\"获取 DeepSeek 模型名称\"\"\"\n",
    "        return os.getenv(\"DEEPSEEK_MODEL\", \"deepseek-chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPServer:\n",
    "    \"\"\"MCP 服务器管理类，处理服务器连接和工具执行\"\"\"\n",
    "    def __init__(self, server_path: str) -> None:\n",
    "        \"\"\"\n",
    "        初始化服务器管理器\n",
    "        \n",
    "        Args:\n",
    "            server_path: 服务器脚本路径\n",
    "        \"\"\"\n",
    "        self.server_path = server_path\n",
    "        self.session: Optional[ClientSession] = None\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self._cleanup_lock = asyncio.Lock()\n",
    "        \n",
    "\n",
    "    async def initialize(self) -> None:\n",
    "        \"\"\"初始化服务器连接，包含重试机制\"\"\"\n",
    "        max_retries = 3\n",
    "        retry_delay = 1.0\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                if not os.path.exists(self.server_path):\n",
    "                    raise FileNotFoundError(f\"找不到服务器文件: {self.server_path}\")\n",
    "                #这里可以增加使用在线MCP服务器的处理逻辑，参考https://github.com/langchain-ai/langchain-mcp-adapters\n",
    "                \n",
    "                server_params = StdioServerParameters(\n",
    "                    command='python',\n",
    "                    args=[self.server_path],\n",
    "                    env=None\n",
    "                )\n",
    "                \n",
    "                stdio_transport = await self.exit_stack.enter_async_context(\n",
    "                    stdio_client(server_params)\n",
    "                )\n",
    "                stdio, write = stdio_transport\n",
    "                \n",
    "                self.session = await self.exit_stack.enter_async_context(\n",
    "                    ClientSession(stdio, write)\n",
    "                )\n",
    "                await self.session.initialize()\n",
    "                logger.info(\"成功连接到 MCP 服务器\")\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"第 {attempt + 1}/{max_retries} 次尝试失败: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    await asyncio.sleep(retry_delay)\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "    async def list_tools(self) -> List[BaseTool]:\n",
    "        \"\"\"获取服务器提供的可用工具列表\"\"\"\n",
    "        if not self.session:\n",
    "            raise RuntimeError(\"服务器未初始化\")\n",
    "        # LangChain方式获取可用工具列表\n",
    "        tools = await load_mcp_tools(self.session)\n",
    "        logger.info(f\"成功加载工具: {[tool.name for tool in tools]}\")\n",
    "        return tools\n",
    "\n",
    "    async def cleanup(self) -> None:\n",
    "        \"\"\"清理服务器资源\"\"\"\n",
    "        async with self._cleanup_lock:\n",
    "            try:\n",
    "                await self.exit_stack.aclose()\n",
    "                self.session = None\n",
    "                logger.info(\"服务器资源清理完成\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"清理过程中出错: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213aac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPClient:\n",
    "    \"\"\"MCP 客户端实现，集成了 DeepSeek API\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Configuration) -> None:\n",
    "        \"\"\"\n",
    "        初始化 MCP 客户端\n",
    "        \n",
    "        Args:\n",
    "            config: 配置对象\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.server: Optional[MCPServer] = None\n",
    "        self.llm_client = ChatOpenAI(\n",
    "            api_key=config.api_key,\n",
    "            base_url=config.base_url,\n",
    "            model=config.model\n",
    "        )\n",
    "        \n",
    "    async def initialize(self) -> None:\n",
    "        \"\"\"初始化客户端并连接到服务器\"\"\"\n",
    "        server_path = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"server\",\n",
    "            \"weather_server.py\"\n",
    "        )\n",
    "        self.server = MCPServer(server_path)\n",
    "        await self.server.initialize()\n",
    "        \n",
    "    async def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        处理用户查询，集成工具调用，支持多轮工具交互\n",
    "\n",
    "        Args:\n",
    "            query: 用户查询字符串\n",
    "\n",
    "        Returns:\n",
    "            处理后的响应结果\n",
    "        \"\"\"\n",
    "        if not self.server:\n",
    "            raise RuntimeError(\"客户端未初始化\")\n",
    "\n",
    "        # 创建提示模板\n",
    "        prompt = SystemMessage(content=\"\"\"你是一个专注于天气信息的助手...（详细系统提示内容）\"\"\")\n",
    "        \n",
    "        # 获取工具\n",
    "        tools = await self.server.list_tools()\n",
    "\n",
    "        # 创建ReAct Agent\n",
    "        logger.info(\"正在创建agent...\")\n",
    "        agent = create_react_agent(\n",
    "            model=self.llm_client,  \n",
    "            tools=tools,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        logger.info(\"Agent创建成功\")\n",
    "\n",
    "        # 发送查询\n",
    "        logger.info(\"正在发送天气查询...\")\n",
    "        agent_response = await agent.ainvoke({\n",
    "            \"messages\": query\n",
    "        })\n",
    "\n",
    "        # 返回响应\n",
    "        return agent_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8e62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:成功连接到 MCP 服务器\n",
      "INFO:__main__:成功加载工具: ['get_weather']\n",
      "INFO:__main__:正在创建agent...\n",
      "INFO:__main__:Agent创建成功\n",
      "INFO:__main__:正在发送天气查询...\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/tmp/ipykernel_16916/3875618828.py:11: RuntimeWarning: coroutine 'MCPClient.process_query' was never awaited\n",
      "  response = await client.process_query(query)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:__main__:查询响应: {'messages': [HumanMessage(content='请告诉我今天北京的天气', additional_kwargs={}, response_metadata={}, id='ab1677bb-2614-478a-b02d-826b6533e71d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_3cb78a8b-2f5c-4b32-ac64-32419124d0d5', 'function': {'arguments': '{\"city\":\"北京\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 114, 'total_tokens': 134, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 50}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '943093b1-dc0b-4f43-9158-afd181ca49b5', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--cf5de6c6-e3ea-495b-9964-dbfdfa7c5684-0', tool_calls=[{'name': 'get_weather', 'args': {'city': '北京'}, 'id': 'call_0_3cb78a8b-2f5c-4b32-ac64-32419124d0d5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 114, 'output_tokens': 20, 'total_tokens': 134, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}}), ToolMessage(content='晴，25°C', name='get_weather', id='27af4e3a-83ad-452a-902f-d901a430b7d5', tool_call_id='call_0_3cb78a8b-2f5c-4b32-ac64-32419124d0d5'), AIMessage(content='今天北京的天气是晴天，气温为25°C。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 150, 'total_tokens': 162, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 22}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': 'd25beba4-e535-4d27-90e0-ce4c24888097', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--e7f5a505-7163-4333-bd90-c244856a4e12-0', usage_metadata={'input_tokens': 150, 'output_tokens': 12, 'total_tokens': 162, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "global logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "config = Configuration()\n",
    "client = MCPClient(config)\n",
    "\n",
    "await client.initialize()\n",
    "\n",
    "query = \"请告诉我今天北京的天气\"\n",
    "response = await client.process_query(query)\n",
    "\n",
    "logger.info(f\"查询响应: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCPvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
