Content from https://www.21jingji.com/article/20250424/herald/a894decd906f8af140da9b8d12052579.html:
南方财经全媒体记者林本森 广州报道
在经历近两年的调整后，科大讯飞（002230.SZ）业绩重返双位数增长通道。
科大讯飞2024年财报显示，全年实现营业收入233.43亿元，同比增长18.79%，突破了200亿元大关，时隔两年重回双位数增长。当期归母净利润为5.6亿元，扣除非经常性损益后的净利润实现了近60%增长。
面对技术浪潮与市场变化，科大讯飞继续押注公司在AI（人工智能）领域的战略布局方向。
公司管理层在多个场合强调，将坚定执行以“讯飞星火”认知大模型为核心的“1+N”战略，抓住通用人工智能（AGI）时代的“根”红利。
营收重返双位数增长通道
数据显示，科大讯飞全年实现营业总收入233.43亿元，相较于2023年的196.50亿元，增长了18.79%，毛利较上年同期增长了15.68亿元。
科大讯飞主营业务的增长主要得益于公司在智慧教育、开放平台及消费者业务等板块的良好表现。
具体而言，开放平台及消费者业务实现收入78.86亿元，同比增长27.58%，蝉联公司第一大业务板块，营收结构持续改善。细分来看，平台消费者业务中，开放平台、智能硬件分别实现收入51.72亿元、20.23亿元、6.91亿元，分别同比增长31.33%、25.07%。
智慧教育业务全年营收达72.3亿元，同比增长近30%，占主营业务收入比重从28.31%提升至30.97%。公司董事长刘庆峰透露，学习机2024年全年收入增长100%，2025年Q1收入增长接近翻倍，保持了强劲的增长势头。
此外，汽车、医疗、企业AI业务保持快速增长，分别实现收入9.89亿元、6.92亿元、6.43亿元，分别同比增长42.16%、28.18%、122.56%。
科大讯飞的现金流状况在2024年得到大幅改善。2024年，科大讯飞的经营活动产生的现金流量净额达到24.95亿元，较上年同期的3.50亿元增长613.40%。
“主要通过优化回款工作机制创下这一纪录，包括加强常态化回款催收工作、形成了更好现金流的GBC业务架构、G端业务通过优选客户和政府专项债提升了回款及时性。”科大讯飞总裁吴晓如介绍，公司在2024年初专门成立回款部门，帮助前端销售同事加强回款工作。
这与科大讯飞的业务架构有关。科大讯飞确立“做优C端、做强B端、优选G端”战略。“C端收入占比持续提升，销售回款率很高，B端首选现金流有保障的优质行业，G端则是选择财政情况较好的区域进行合作。”吴晓如说。
科大讯飞CFO段大为表示，将通过业务结构改善、费用控制等方式提高盈利能力。公司将保持“经营上的自我要求和约束”，提高毛利率，包括严格控制成本和费用，不断调整方向聚焦核心业务，识别有规模化成长潜力的领域并努力使其充分释放。据了解，公司近两年产线数量从60条缩减至46条。
这些成果在今年一季度得到体现。科大讯飞今年一季度营收达46.58亿元，同比增长27.74%，归母净利润、扣非净利润分别同比增长35.68%和48.29%，经营性现金流量较去年同期改善6.7亿元。
坚持底座大模型自研
科大讯飞的人工智能业务发展，遵循其提出的“顶天立地”战略。“顶天”意指核心技术保持国际领先，“立地”则强调技术成果的大规模产业化应用。
围绕讯飞星火大模型这一核心技术底座，科大讯飞构建了AI行业应用、AI开放平台和AI消费者产品三大商业化落地体系，旨在将AI能力广泛赋能千行百业。
据科大讯飞财报披露，公司在AI行业应用层面的多个领域已取得可见进展。
以智慧教育板块业务为例，这是科大讯飞的传统优势领域，其“星火教师助手”等产品已在广东、江苏、江西等多省推广应用，公司数据显示教师活跃度近90%，周均使用超5.1次，能帮助教师教学设计减负超55%，课件制作提效近65%。
这得益于科大讯飞在AI路线上的方向判断和长期坚持，推动公司“1+N”战略正逐步从规划走向现实。
在当前大模型技术路线选择多样，部分厂商选择依赖开源模型甚至放弃基础模型研发的背景下，科大讯飞坚持投入自研底座大模型，并坚定地走国产化算力路线。其背后是基于技术判断、市场需求、成本考量、国家战略等多维度的深层战略抉择。
科大讯飞董事长刘庆峰明确表示，“我们有能力，国家有需求”，公司有能力将底座模型做到业界第一梯队。
刘庆峰称，基于自主研发的底座模型训练出来的行业模型，在尺寸灵活性、适配深度、最终效果上，比基于开源模型训练出来的行业模型要好。
据了解，科大讯飞发布的讯飞星火X1模型，据称在70B参数规模下，深度推理能力已达到行业先进水平，效果可比肩更大参数量的模型（如满血版DeepSeek-R1 671B）。
尤为关键的是，这一成果主要是在国产华为昇腾910B算力平台上训练和优化的。尽管国产算力生态在软件、工具链等方面仍需完善，但科大讯飞通过与华为等伙伴的深度合作，率先攻克了万卡高速互联组网、计算通信隐藏、训练推理强交互、国产算子优化等一系列难题，验证了在国产算力平台上训练出顶尖大模型的可行性与潜力。
刘庆峰认为，在国产算力平台上建设底座大模型，对国家具有战略意义，在市场上也有独特的应用需要。“无论是像央国企，还是如安全等重要行业，对自主可控的底座大模型的需求非常迫切，而讯飞是基于国产算力训练，各方面的可靠性都更胜一筹，也更受相关客户和国家主管部门的信任。”
不仅如此，坚持自研底座大模型也是满足行业深度应用刚需的必然选择。原因在于，通用开源模型虽然降低了使用门槛，但在可靠性、安全性、可控性以及特定行业场景的适配深度上，往往难以满足高标准要求。
刘庆峰透露，不少央企国企及关键行业客户在年初试点开源模型后，遇到了幻觉多、存在安全漏洞等问题，最终转向寻求科大讯飞提供基于自研模型的专业解决方案。因为科大讯飞基于完全自主可控的大模型底座进行行业定制时，可以实现更灵活的参数规模调整和更深度的训练优化，从而更好地满足教育、医疗、司法、金融等领域对高精度、高可靠性的核心需求。
据其透露，基于自研底座的行业大模型相比通用大模型效果平均可提升10%，在此基础上做场景定制调优，效果还可进一步提升10%—20%。
刘庆峰表示，尽管在适配国产算力的初期需要付出额外的成本和时间代价，但科大讯飞通过深度优化，已在国产平台上展现出潜在的成本优势。
根据其在业绩说明会上的信息，同样基于国产昇腾910B平台，讯飞星火X1进行行业落地定制（SFT和强化学习）所需的硬件卡数仅为友商满血版DeepSeek的1/16。
在推理方面，部署星火X1模型仅需4张华为910B卡即可完成私有化部署，相较于友商满血版R1模型，在性能类似情况下硬件投入仅需1/8，且在小规模并发推理服务上，单台服务器支持的并发路数高三倍。
科大讯飞的这一选择，不仅关乎企业自身的核心竞争力与长远发展，也在一定程度上体现了国内领先科技企业在推动技术自主创新、保障产业链供应链安全方面的责任与探索。
在波澜壮阔的AI时代，竞争注定激烈，而方向选择，或许更为重要。

